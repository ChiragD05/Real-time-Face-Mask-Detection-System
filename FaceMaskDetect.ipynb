{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0221422f-2e2f-4008-8c78-01d2a4d7d5e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-07 15:12:21.911632: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import cv2\n",
    "from mtcnn import MTCNN\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from torchvision import transforms, models\n",
    "from IPython.display import display, clear_output\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7b2fe92-d1be-47f5-8555-1fa497c5f378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Model loaded successfully and ready for inference.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "from collections import OrderedDict\n",
    "\n",
    "# Define the same model architecture used during training\n",
    "class FaceMaskModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FaceMaskModel, self).__init__()\n",
    "        self.model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
    "        num_ftrs = self.model.fc.in_features\n",
    "        self.model.fc = nn.Linear(num_ftrs, 2)  # Binary classification\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# Instantiate model\n",
    "model = FaceMaskModel()\n",
    "\n",
    "# Load the saved state_dict\n",
    "state_dict = torch.load(\"FaceMaskModel.pt\", map_location=torch.device(\"cpu\"))\n",
    "\n",
    "# Remove 'module.' prefix if model was saved with DataParallel\n",
    "if list(state_dict.keys())[0].startswith(\"module.\"):\n",
    "    new_state_dict = OrderedDict()\n",
    "    for k, v in state_dict.items():\n",
    "        new_key = k.replace(\"module.\", \"\")\n",
    "        new_state_dict[new_key] = v\n",
    "    model.load_state_dict(new_state_dict)\n",
    "else:\n",
    "    model.load_state_dict(state_dict)\n",
    "\n",
    "# Set model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "print(\"‚úÖ Model loaded successfully and ready for inference.\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2a6d9f1-f495-4138-b42e-ada633ce3c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Preprocessing ---\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406),\n",
    "                         (0.229, 0.224, 0.225))\n",
    "])\n",
    "labels = ['Without Mask', 'With Mask']\n",
    "detector = MTCNN()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b298dc2-9b3c-48f4-979d-4725fbb04787",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@34.749] global cap_gstreamer.cpp:1173 isPipelinePlaying OpenCV | GStreamer warning: GStreamer: pipeline have not been created\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìπ Press 'q' to stop the video stream\n"
     ]
    }
   ],
   "source": [
    "# --- Video Stream Setup ---\n",
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    print(\"‚ùå Camera could not be opened\")\n",
    "    exit()\n",
    "\n",
    "print(\"üìπ Press 'q' to stop the video stream\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1358074-d7e5-43f3-9538-aa5ca3aaf29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Main loop\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"‚ùå Failed to capture frame\")\n",
    "        break\n",
    "\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    boxes = detector.detect_faces(rgb_frame)\n",
    "\n",
    "    for box in boxes:\n",
    "        x, y, width, height = box['box']\n",
    "        x, y = max(0, x), max(0, y)\n",
    "        face = frame[y:y+height, x:x+width]\n",
    "\n",
    "        if face.size == 0:\n",
    "            continue\n",
    "\n",
    "        pil_face = Image.fromarray(cv2.cvtColor(face, cv2.COLOR_BGR2RGB))\n",
    "        transformed_face = transform(pil_face).unsqueeze(0)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(transformed_face)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        label = labels[predicted.item()]\n",
    "        color = (0, 255, 0) if predicted.item() == 1 else (0, 0, 255)\n",
    "\n",
    "        cv2.rectangle(frame, (x, y), (x+width, y+height), color, 2)\n",
    "        cv2.putText(frame, label, (x, y-10),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, 2)\n",
    "\n",
    "    cv2.imshow(\"Face Mask Detection\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f54820-29cd-4221-a24d-96d44443858e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Face Mask)",
   "language": "python",
   "name": "facemaskenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
